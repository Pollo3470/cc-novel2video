"""
Gemini API ç»Ÿä¸€å°è£…

æä¾›å›¾ç‰‡ç”Ÿæˆå’Œè§†é¢‘ç”Ÿæˆçš„ç»Ÿä¸€æ¥å£ã€‚
"""

import os
import time
import base64
import functools
import random
import asyncio
from pathlib import Path
from typing import Optional, List, Union, Tuple, Type, Dict
from PIL import Image
import io
import threading
from collections import deque

# å¯é‡è¯•çš„é”™è¯¯ç±»å‹
RETRYABLE_ERRORS: Tuple[Type[Exception], ...] = (
    ConnectionError,
    TimeoutError,
)

# å°è¯•å¯¼å…¥ Google API é”™è¯¯ç±»å‹
try:
    from google.api_core import exceptions as google_exceptions
    from google import genai # Import genai to access its errors

    RETRYABLE_ERRORS = RETRYABLE_ERRORS + (
        google_exceptions.ResourceExhausted,  # 429 Too Many Requests
        google_exceptions.ServiceUnavailable,  # 503
        google_exceptions.DeadlineExceeded,    # è¶…æ—¶
        google_exceptions.InternalServerError, # 500
        genai.errors.ClientError, # 4xx errors from new SDK
        genai.errors.ServerError, # 5xx errors from new SDK
    )
except ImportError:
    pass


class RateLimiter:
    """
    å¤šæ¨¡å‹æ»‘åŠ¨çª—å£é™æµå™¨
    """
    def __init__(self, limits_dict: Dict[str, int] = None):
        """
        Args:
            limits_dict: {model_name: rpm} å­—å…¸ã€‚ä¾‹å¦‚ {"gemini-3-pro-image-preview": 20}
        """
        self.limits = limits_dict or {}
        # å­˜å‚¨è¯·æ±‚æ—¶é—´æˆ³ï¼š{model_name: deque([timestamp1, timestamp2, ...])}
        self.request_logs: Dict[str, deque] = {}
        self.lock = threading.Lock()

    def acquire(self, model_name: str):
        """
        é˜»å¡ç›´åˆ°è·å¾—ä»¤ç‰Œ
        """
        if model_name not in self.limits:
            return  # è¯¥æ¨¡å‹æ— é™æµé…ç½®

        limit = self.limits[model_name]
        if limit <= 0:
            return

        with self.lock:
            if model_name not in self.request_logs:
                self.request_logs[model_name] = deque()

            log = self.request_logs[model_name]

            while True:
                now = time.time()

                # æ¸…ç†è¶…è¿‡ 60 ç§’çš„æ—§è®°å½•
                while log and now - log[0] > 60:
                    log.popleft()

                # å¼ºåˆ¶å¢åŠ è¯·æ±‚é—´éš”ï¼ˆç”¨æˆ·è¦æ±‚ > 3sï¼‰
                # å³ä½¿è·å¾—äº†ä»¤ç‰Œï¼Œä¹Ÿè¦ç¡®ä¿è·ç¦»ä¸Šä¸€æ¬¡è¯·æ±‚è‡³å°‘ 3s
                # è·å–æœ€æ–°çš„è¯·æ±‚æ—¶é—´ï¼ˆå¯èƒ½æ˜¯å…¶ä»–çº¿ç¨‹åˆšåˆšå†™å…¥çš„ï¼‰
                min_gap = float(os.environ.get('GEMINI_REQUEST_GAP', 3.1))
                if log:
                    last_request = log[-1]
                    gap = time.time() - last_request
                    if gap < min_gap:
                        time.sleep(min_gap - gap)
                        # æ›´æ–°æ—¶é—´ï¼Œé‡æ–°æ£€æŸ¥
                        continue

                if len(log) < limit:
                    # è·å–ä»¤ç‰ŒæˆåŠŸ
                    log.append(time.time())
                    return

                # è¾¾åˆ°é™åˆ¶ï¼Œè®¡ç®—ç­‰å¾…æ—¶é—´
                # ç­‰å¾…ç›´åˆ°æœ€æ—©çš„è®°å½•è¿‡æœŸ
                wait_time = 60 - (now - log[0]) + 0.1  # å¤šåŠ  0.1s ç¼“å†²
                if wait_time > 0:
                    time.sleep(wait_time)

    async def acquire_async(self, model_name: str):
        """
        å¼‚æ­¥é˜»å¡ç›´åˆ°è·å¾—ä»¤ç‰Œ
        """
        if model_name not in self.limits:
            return  # è¯¥æ¨¡å‹æ— é™æµé…ç½®

        limit = self.limits[model_name]
        if limit <= 0:
            return

        while True:
            with self.lock:
                now = time.time()

                if model_name not in self.request_logs:
                    self.request_logs[model_name] = deque()

                log = self.request_logs[model_name]

                # æ¸…ç†è¶…è¿‡ 60 ç§’çš„æ—§è®°å½•
                while log and now - log[0] > 60:
                    log.popleft()

                min_gap = float(os.environ.get('GEMINI_REQUEST_GAP', 3.1))
                wait_needed = 0
                if log:
                    last_request = log[-1]
                    gap = now - last_request
                    if gap < min_gap:
                        # é‡Šæ”¾é”åå¼‚æ­¥ç­‰å¾…
                        wait_needed = min_gap - gap

                if len(log) >= limit:
                    # è¾¾åˆ°é™åˆ¶ï¼Œè®¡ç®—ç­‰å¾…æ—¶é—´
                    wait_needed = max(wait_needed, 60 - (now - log[0]) + 0.1)

                if wait_needed == 0 and len(log) < limit:
                    # è·å–ä»¤ç‰ŒæˆåŠŸ
                    log.append(now)
                    return

            # åœ¨é”å¤–å¼‚æ­¥ç­‰å¾…
            if wait_needed > 0:
                await asyncio.sleep(wait_needed)
            else:
                await asyncio.sleep(0.1)  # çŸ­æš‚è®©å‡ºæ§åˆ¶æƒ


def with_retry(
    max_attempts: int = 5,
    backoff_seconds: Tuple[int, ...] = (2, 4, 8, 16, 32),
    retryable_errors: Tuple[Type[Exception], ...] = RETRYABLE_ERRORS
):
    """
    å¸¦æŒ‡æ•°é€€é¿çš„é‡è¯•è£…é¥°å™¨
    """
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            # å°è¯•æå– output_path ä»¥ä¾¿åœ¨æ—¥å¿—ä¸­æ˜¾ç¤ºä¸Šä¸‹æ–‡
            output_path = kwargs.get('output_path')
            # å¦‚æœæ˜¯ä½ç½®å‚æ•°ï¼Œgenerate_image çš„ output_path æ˜¯ç¬¬ 5 ä¸ªå‚æ•° (self, prompt, ref, ar, output_path)
            if not output_path and len(args) > 4:
                output_path = args[4]

            context_str = ""
            if output_path:
                context_str = f"[{Path(output_path).name}] "

            last_error = None
            for attempt in range(max_attempts):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    # Catch ALL exceptions and check if they look like a retryable error
                    last_error = e
                    should_retry = False

                    # Check if it's in our explicit list
                    if isinstance(e, retryable_errors):
                        should_retry = True

                    # Check by string analysis (catch-all for 429/500/503)
                    error_str = str(e)
                    if '429' in error_str or 'RESOURCE_EXHAUSTED' in error_str:
                        should_retry = True
                    elif '500' in error_str or 'InternalServerError' in error_str:
                        should_retry = True
                    elif '503' in error_str or 'ServiceUnavailable' in error_str:
                        should_retry = True

                    if not should_retry:
                        raise e

                    if attempt < max_attempts - 1:
                        # ç¡®ä¿ä¸è¶…è¿‡ backoff æ•°ç»„é•¿åº¦
                        backoff_idx = min(attempt, len(backoff_seconds) - 1)
                        base_wait = backoff_seconds[backoff_idx]
                        jitter = random.uniform(0, 2)  # 0-2ç§’éšæœºæŠ–åŠ¨
                        wait_time = base_wait + jitter
                        print(f"âš ï¸  {context_str}æ•è·å¼‚å¸¸: {type(e).__name__} - {str(e)[:100]}...")
                        print(f"âš ï¸  {context_str}é‡è¯• {attempt + 1}/{max_attempts - 1}ï¼Œ{wait_time:.1f}ç§’å...")
                        time.sleep(wait_time)
            raise last_error
        return wrapper
    return decorator


def with_retry_async(
    max_attempts: int = 5,
    backoff_seconds: Tuple[int, ...] = (2, 4, 8, 16, 32),
    retryable_errors: Tuple[Type[Exception], ...] = RETRYABLE_ERRORS
):
    """
    å¼‚æ­¥å‡½æ•°é‡è¯•è£…é¥°å™¨ï¼Œå¸¦æŒ‡æ•°é€€é¿å’ŒéšæœºæŠ–åŠ¨
    """
    def decorator(func):
        @functools.wraps(func)
        async def wrapper(*args, **kwargs):
            # å°è¯•æå– output_path ä»¥ä¾¿åœ¨æ—¥å¿—ä¸­æ˜¾ç¤ºä¸Šä¸‹æ–‡
            output_path = kwargs.get('output_path')
            if not output_path and len(args) > 4:
                output_path = args[4]

            context_str = ""
            if output_path:
                context_str = f"[{Path(output_path).name}] "

            last_error = None
            for attempt in range(max_attempts):
                try:
                    return await func(*args, **kwargs)
                except Exception as e:
                    last_error = e
                    should_retry = False

                    if isinstance(e, retryable_errors):
                        should_retry = True

                    error_str = str(e)
                    if '429' in error_str or 'RESOURCE_EXHAUSTED' in error_str:
                        should_retry = True
                    elif '500' in error_str or 'InternalServerError' in error_str:
                        should_retry = True
                    elif '503' in error_str or 'ServiceUnavailable' in error_str:
                        should_retry = True

                    if not should_retry:
                        raise e

                    if attempt < max_attempts - 1:
                        backoff_idx = min(attempt, len(backoff_seconds) - 1)
                        base_wait = backoff_seconds[backoff_idx]
                        jitter = random.uniform(0, 2)  # 0-2ç§’éšæœºæŠ–åŠ¨
                        wait_time = base_wait + jitter
                        print(f"âš ï¸  {context_str}æ•è·å¼‚å¸¸: {type(e).__name__} - {str(e)[:100]}...")
                        print(f"âš ï¸  {context_str}é‡è¯• {attempt + 1}/{max_attempts - 1}ï¼Œ{wait_time:.1f}ç§’å...")
                        await asyncio.sleep(wait_time)
            raise last_error
        return wrapper
    return decorator


# åŠ è½½ .env æ–‡ä»¶
try:
    from dotenv import load_dotenv
    # ä»é¡¹ç›®æ ¹ç›®å½•åŠ è½½ .env
    env_path = Path(__file__).parent.parent / '.env'
    if env_path.exists():
        load_dotenv(env_path)
    else:
        # ä¹Ÿå°è¯•ä»å½“å‰å·¥ä½œç›®å½•åŠ è½½
        load_dotenv()
except ImportError:
    pass  # python-dotenv æœªå®‰è£…æ—¶è·³è¿‡


class GeminiClient:
    """Gemini API å®¢æˆ·ç«¯å°è£…"""

    # è·³è¿‡åç§°æ¨æ–­çš„æ–‡ä»¶åæ¨¡å¼
    SKIP_NAME_PATTERNS = ('grid_', 'scene_', 'storyboard_', 'output_')

    def __init__(self, api_key: Optional[str] = None, rate_limiter: Optional[RateLimiter] = None):
        """
        åˆå§‹åŒ– Gemini å®¢æˆ·ç«¯

        æ”¯æŒä¸¤ç§åç«¯ï¼š
        - AI Studioï¼ˆé»˜è®¤ï¼‰ï¼šä½¿ç”¨ GEMINI_API_KEY
        - Vertex AIï¼šä½¿ç”¨ GCP é¡¹ç›®å’Œåº”ç”¨é»˜è®¤å‡­æ®

        é€šè¿‡ç¯å¢ƒå˜é‡ GEMINI_BACKEND åˆ‡æ¢ï¼š
        - GEMINI_BACKEND=aistudioï¼ˆé»˜è®¤ï¼‰
        - GEMINI_BACKEND=vertex

        Args:
            api_key: API å¯†é’¥ï¼ˆä»… AI Studio æ¨¡å¼ï¼‰ï¼Œé»˜è®¤ä»ç¯å¢ƒå˜é‡ GEMINI_API_KEY è¯»å–
            rate_limiter: å¯é€‰çš„é™æµå™¨å®ä¾‹
        """
        from google import genai
        from google.genai import types

        self.types = types
        self.rate_limiter = rate_limiter
        self.backend = os.environ.get('GEMINI_BACKEND', 'aistudio').lower()
        self.credentials = None  # ç”¨äº Vertex AI æ¨¡å¼
        self.project_id = None   # ç”¨äº Vertex AI æ¨¡å¼
        self.gcs_bucket = None   # ç”¨äº Vertex AI æ¨¡å¼çš„è§†é¢‘å»¶é•¿è¾“å‡º

        if self.backend == 'vertex':
            # Vertex AI æ¨¡å¼ï¼ˆä½¿ç”¨ JSON æœåŠ¡è´¦å·å‡­è¯ï¼‰
            from google.oauth2 import service_account
            import json as json_module

            # æŸ¥æ‰¾å‡­è¯æ–‡ä»¶
            credentials_dir = Path(__file__).parent.parent / 'vertex_keys'
            credentials_files = list(credentials_dir.glob('*.json')) if credentials_dir.exists() else []

            if not credentials_files:
                raise ValueError(
                    "æœªæ‰¾åˆ° Vertex AI å‡­è¯æ–‡ä»¶\n"
                    "è¯·å°†æœåŠ¡è´¦å· JSON æ–‡ä»¶æ”¾å…¥ vertex_keys/ ç›®å½•"
                )

            credentials_file = credentials_files[0]  # å–ç¬¬ä¸€ä¸ªæ–‡ä»¶

            # ä»å‡­è¯æ–‡ä»¶è¯»å–é¡¹ç›® ID
            with open(credentials_file) as f:
                creds_data = json_module.load(f)
            self.project_id = creds_data.get('project_id')

            if not self.project_id:
                raise ValueError(f"å‡­è¯æ–‡ä»¶ {credentials_file} ä¸­æœªæ‰¾åˆ° project_id")

            # è¯»å– GCS bucket é…ç½®ï¼ˆç”¨äºè§†é¢‘å»¶é•¿ï¼‰
            self.gcs_bucket = os.environ.get('VERTEX_GCS_BUCKET')

            # åŠ è½½æœåŠ¡è´¦å·å‡­è¯å¹¶æ·»åŠ å¿…è¦çš„ scopes
            VERTEX_SCOPES = [
                "https://www.googleapis.com/auth/cloud-platform",
                "https://www.googleapis.com/auth/generative-language",
            ]
            self.credentials = service_account.Credentials.from_service_account_file(
                str(credentials_file),
                scopes=VERTEX_SCOPES
            )

            self.client = genai.Client(
                vertexai=True,
                project=self.project_id,
                location="us-central1",
                credentials=self.credentials,
            )
            print(f"âœ“ ä½¿ç”¨ Vertex AI åç«¯ï¼ˆå‡­è¯: {credentials_file.name}ï¼‰")
        else:
            # AI Studio æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰
            self.api_key = api_key or os.environ.get('GEMINI_API_KEY')
            if not self.api_key:
                raise ValueError(
                    "GEMINI_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®\n"
                    "è¯·åœ¨ .env æ–‡ä»¶ä¸­æ·»åŠ ï¼šGEMINI_API_KEY=your-api-key"
                )

            self.client = genai.Client(api_key=self.api_key)
            print("âœ“ ä½¿ç”¨ AI Studio åç«¯")

        # æ¨¡å‹é…ç½®ï¼ˆä¸¤ç§åç«¯ä½¿ç”¨ç›¸åŒçš„æ¨¡å‹åï¼‰
        self.IMAGE_MODEL = "gemini-3-pro-image-preview"
        self.VIDEO_MODEL = "veo-3.1-generate-preview"

    def _extract_name_from_path(self, image: Union[str, Path, Image.Image]) -> Optional[str]:
        """
        ä»å›¾ç‰‡è·¯å¾„æ¨æ–­åç§°

        Args:
            image: å›¾ç‰‡è·¯å¾„æˆ– PIL Image å¯¹è±¡

        Returns:
            æ¨æ–­å‡ºçš„åç§°ï¼Œæˆ– Noneï¼ˆæ— æ³•æ¨æ–­æ—¶ï¼‰

        Examples:
            characters/å§œæœˆèŒ´.png â†’ "å§œæœˆèŒ´"
            clues/ç‰ä½©.png â†’ "ç‰ä½©"
            storyboards/grid_001.png â†’ None (è·³è¿‡)
            PIL.Image.Image â†’ None (è·³è¿‡)
        """
        # PIL Image å¯¹è±¡æ— æ³•æ¨æ–­
        if isinstance(image, Image.Image):
            return None

        path = Path(image)
        filename = path.stem  # ä¸å«æ‰©å±•åçš„æ–‡ä»¶å

        # è·³è¿‡é€šç”¨æ–‡ä»¶åæ¨¡å¼
        for pattern in self.SKIP_NAME_PATTERNS:
            if filename.startswith(pattern):
                return None

        return filename

    def _build_contents_with_labeled_refs(
        self,
        prompt: str,
        reference_images: Optional[List[Union[str, Path, Image.Image]]] = None
    ) -> List:
        """
        æ„å»ºå¸¦åç§°æ ‡ç­¾çš„ contents åˆ—è¡¨

        æ ¼å¼ï¼š[åç§°1, å›¾ç‰‡1, åç§°2, å›¾ç‰‡2, ..., prompt]
        - æ¯å¼ å‚è€ƒå›¾ç‰‡å‰æ·»åŠ åç§°æ ‡ç­¾ï¼ˆå¦‚æœèƒ½æ¨æ–­ï¼‰
        - prompt æ”¾åœ¨æœ€å

        Args:
            prompt: å›¾ç‰‡ç”Ÿæˆæç¤ºè¯
            reference_images: å‚è€ƒå›¾ç‰‡åˆ—è¡¨

        Returns:
            æ„å»ºå¥½çš„ contents åˆ—è¡¨
        """
        contents = []

        # æ·»åŠ å¸¦æ ‡ç­¾çš„å‚è€ƒå›¾ç‰‡
        if reference_images:
            labeled_refs = []
            for img in reference_images:
                name = self._extract_name_from_path(img)
                if name:
                    labeled_refs.append(name)
                    contents.append(name)

                # åŠ è½½å›¾ç‰‡
                if isinstance(img, (str, Path)):
                    loaded_img = Image.open(img)
                else:
                    loaded_img = img
                contents.append(loaded_img)

            # æ‰“å°æ—¥å¿—
            if labeled_refs:
                print(f"ğŸ“ å‚è€ƒå›¾ç‰‡æ ‡ç­¾: {', '.join(labeled_refs)}")

        # prompt æ”¾æœ€å
        contents.append(prompt)

        return contents

    def _prepare_image_config(self, aspect_ratio: str):
        """æ„å»ºå›¾ç‰‡ç”Ÿæˆé…ç½®"""
        return self.types.GenerateContentConfig(
            response_modalities=['TEXT', 'IMAGE'],
            image_config=self.types.ImageConfig(
                aspect_ratio=aspect_ratio
            )
        )

    def _process_image_response(
        self,
        response,
        output_path: Optional[Union[str, Path]] = None
    ) -> Image.Image:
        """è§£æå›¾ç‰‡ç”Ÿæˆå“åº”å¹¶å¯é€‰ä¿å­˜"""
        for part in response.parts:
            if part.inline_data is not None:
                image = part.as_image()
                if output_path:
                    output_path = Path(output_path)
                    output_path.parent.mkdir(parents=True, exist_ok=True)
                    image.save(output_path)
                return image
        raise RuntimeError("API æœªè¿”å›å›¾ç‰‡")

    @with_retry(max_attempts=5, backoff_seconds=(2, 4, 8, 16, 32))
    def generate_image(
        self,
        prompt: str,
        reference_images: Optional[List[Union[str, Path, Image.Image]]] = None,
        aspect_ratio: str = "9:16",
        output_path: Optional[Union[str, Path]] = None
    ) -> Image.Image:
        """
        ç”Ÿæˆå›¾ç‰‡

        Args:
            prompt: å›¾ç‰‡ç”Ÿæˆæç¤ºè¯
            reference_images: å‚è€ƒå›¾ç‰‡åˆ—è¡¨ï¼ˆç”¨äºäººç‰©ä¸€è‡´æ€§ï¼‰
            aspect_ratio: å®½é«˜æ¯”ï¼Œé»˜è®¤ 9:16ï¼ˆç«–å±ï¼‰
            output_path: å¯é€‰çš„è¾“å‡ºè·¯å¾„

        Returns:
            ç”Ÿæˆçš„ PIL Image å¯¹è±¡
        """
        # åº”ç”¨é™æµ
        if self.rate_limiter:
            self.rate_limiter.acquire(self.IMAGE_MODEL)

        # æ„å»ºå¸¦åç§°æ ‡ç­¾çš„ contentsï¼ˆå‚è€ƒå›¾åœ¨å‰ï¼Œprompt åœ¨åï¼‰
        contents = self._build_contents_with_labeled_refs(prompt, reference_images)
        config = self._prepare_image_config(aspect_ratio)

        # è°ƒç”¨ API
        response = self.client.models.generate_content(
            model=self.IMAGE_MODEL,
            contents=contents,
            config=config
        )

        return self._process_image_response(response, output_path)

    @with_retry_async(max_attempts=5, backoff_seconds=(2, 4, 8, 16, 32))
    async def generate_image_async(
        self,
        prompt: str,
        reference_images: Optional[List[Union[str, Path, Image.Image]]] = None,
        aspect_ratio: str = "9:16",
        output_path: Optional[Union[str, Path]] = None
    ) -> Image.Image:
        """
        å¼‚æ­¥ç”Ÿæˆå›¾ç‰‡

        ä½¿ç”¨ genai åŸç”Ÿå¼‚æ­¥ API: client.aio.models.generate_content()

        Args:
            prompt: å›¾ç‰‡ç”Ÿæˆæç¤ºè¯
            reference_images: å‚è€ƒå›¾ç‰‡åˆ—è¡¨ï¼ˆç”¨äºäººç‰©ä¸€è‡´æ€§ï¼‰
            aspect_ratio: å®½é«˜æ¯”ï¼Œé»˜è®¤ 9:16ï¼ˆç«–å±ï¼‰
            output_path: å¯é€‰çš„è¾“å‡ºè·¯å¾„

        Returns:
            ç”Ÿæˆçš„ PIL Image å¯¹è±¡
        """
        # åº”ç”¨é™æµ
        if self.rate_limiter:
            await self.rate_limiter.acquire_async(self.IMAGE_MODEL)

        # æ„å»ºå¸¦åç§°æ ‡ç­¾çš„ contentsï¼ˆå‚è€ƒå›¾åœ¨å‰ï¼Œprompt åœ¨åï¼‰
        contents = self._build_contents_with_labeled_refs(prompt, reference_images)
        config = self._prepare_image_config(aspect_ratio)

        # è°ƒç”¨å¼‚æ­¥ API
        response = await self.client.aio.models.generate_content(
            model=self.IMAGE_MODEL,
            contents=contents,
            config=config
        )

        return self._process_image_response(response, output_path)

    @with_retry(max_attempts=3, backoff_seconds=(2, 4, 8))
    def generate_image_with_chat(
        self,
        prompt: str,
        chat_session=None,
        reference_images: Optional[List[Union[str, Path, Image.Image]]] = None
    ) -> tuple:
        """
        ä½¿ç”¨å¤šè½®å¯¹è¯ç”Ÿæˆå›¾ç‰‡ï¼ˆä¿æŒä¸Šä¸‹æ–‡ä¸€è‡´æ€§ï¼‰

        Args:
            prompt: å›¾ç‰‡ç”Ÿæˆæç¤ºè¯
            chat_session: ç°æœ‰çš„å¯¹è¯ä¼šè¯ï¼Œå¦‚æœä¸º None åˆ™åˆ›å»ºæ–°ä¼šè¯
            reference_images: å‚è€ƒå›¾ç‰‡åˆ—è¡¨

        Returns:
            (ç”Ÿæˆçš„å›¾ç‰‡, å¯¹è¯ä¼šè¯) å…ƒç»„
        """
        # åº”ç”¨é™æµ
        if self.rate_limiter:
            self.rate_limiter.acquire(self.IMAGE_MODEL)

        if chat_session is None:
            chat_session = self.client.chats.create(
                model=self.IMAGE_MODEL
            )

        # æ„å»ºå¸¦åç§°æ ‡ç­¾çš„æ¶ˆæ¯å†…å®¹ï¼ˆå‚è€ƒå›¾åœ¨å‰ï¼Œprompt åœ¨åï¼‰
        message_content = self._build_contents_with_labeled_refs(prompt, reference_images)

        # å‘é€æ¶ˆæ¯
        response = chat_session.send_message(message_content)

        # æå–å›¾ç‰‡
        for part in response.parts:
            if part.inline_data is not None:
                image = part.as_image()
                return image, chat_session

        raise RuntimeError("API æœªè¿”å›å›¾ç‰‡")

    @with_retry(max_attempts=3, backoff_seconds=(2, 4, 8))
    def generate_video(
        self,
        prompt: str,
        # ç”Ÿæˆæ¨¡å¼å‚æ•°
        start_image: Optional[Union[str, Path, Image.Image]] = None,
        reference_images: Optional[List[dict]] = None,
        # å»¶é•¿æ¨¡å¼å‚æ•°
        video: Optional[Union[str, Path]] = None,
        # é…ç½®å‚æ•°
        aspect_ratio: str = "9:16",
        duration_seconds: str = "8",
        resolution: str = "720p",
        negative_prompt: str = "background music, BGM, soundtrack, musical accompaniment",
        output_path: Optional[Union[str, Path]] = None,
        output_gcs_uri: Optional[str] = None,
        poll_interval: int = 10,
        max_wait_time: int = 600
    ) -> tuple:
        """
        ç»Ÿä¸€çš„è§†é¢‘ç”Ÿæˆ/å»¶é•¿æ–¹æ³•

        Args:
            prompt: è§†é¢‘ç”Ÿæˆ/å»¶é•¿æç¤ºè¯ï¼ˆæ”¯æŒå¯¹è¯å’ŒéŸ³æ•ˆæè¿°ï¼‰

            # ç”Ÿæˆæ¨¡å¼å‚æ•°
            start_image: èµ·å§‹å¸§å›¾ç‰‡ï¼ˆimage-to-video æ¨¡å¼ï¼‰
            reference_images: å‚è€ƒå›¾ç‰‡åˆ—è¡¨ï¼Œæ ¼å¼ä¸º [{"image": path, "description": str}]

            # å»¶é•¿æ¨¡å¼å‚æ•°
            video: è¦å»¶é•¿çš„è§†é¢‘ï¼Œæ”¯æŒä»¥ä¸‹ç±»å‹ï¼š
                - Video å¯¹è±¡ï¼ˆæ¥è‡ªä¹‹å‰è°ƒç”¨çš„è¿”å›å€¼ï¼‰
                - URI å­—ç¬¦ä¸²ï¼ˆgs:// æˆ– https://ï¼‰
                - æœ¬åœ°è§†é¢‘æ–‡ä»¶è·¯å¾„

            # é…ç½®å‚æ•°
            aspect_ratio: å®½é«˜æ¯”ï¼Œé»˜è®¤ 9:16ï¼ˆç”Ÿæˆæ¨¡å¼ä½¿ç”¨ï¼‰
            duration_seconds: è§†é¢‘æ—¶é•¿ï¼Œå¯é€‰ "4", "6", "8"ï¼ˆç”Ÿæˆæ¨¡å¼ä½¿ç”¨ï¼‰
            resolution: åˆ†è¾¨ç‡ï¼Œå¯é€‰ "720p", "1080p", "4k"ï¼ˆå»¶é•¿æ¨¡å¼å¼ºåˆ¶ 720pï¼‰
            negative_prompt: è´Ÿé¢æç¤ºè¯ï¼ŒæŒ‡å®šä¸æƒ³è¦çš„å…ƒç´ ï¼ˆé»˜è®¤ç¦æ­¢ BGMï¼‰
            output_path: æœ¬åœ°è¾“å‡ºè·¯å¾„
            output_gcs_uri: GCS è¾“å‡ºè·¯å¾„ï¼ˆVertex AI å»¶é•¿æ¨¡å¼å¿…é¡»è®¾ç½®ï¼‰
            poll_interval: è½®è¯¢é—´éš”ï¼ˆç§’ï¼‰
            max_wait_time: æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰

        Returns:
            (output_path, video_ref, video_uri) ä¸‰å…ƒç»„ï¼š
            - output_path: è§†é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœæŒ‡å®šäº† output_pathï¼‰
            - video_ref: Video å¯¹è±¡ï¼Œç”¨äºåç»­ extend_video()
            - video_uri: å­—ç¬¦ä¸² URIï¼Œå¯ä¿å­˜ç”¨äºè·¨ä¼šè¯æ¢å¤

        Examples:
            # 1. ç”Ÿæˆè§†é¢‘ï¼ˆä»èµ·å§‹å¸§ï¼‰
            path, ref, uri = client.generate_video(
                prompt="è§’è‰²ç¼“æ…¢è½¬èº«...",
                start_image="storyboard.png",
                output_path="output.mp4"
            )

            # 2. å»¶é•¿è§†é¢‘ï¼ˆä½¿ç”¨è¿”å›çš„ refï¼‰
            path2, ref2, uri2 = client.generate_video(
                prompt="ç»§ç»­å½“å‰åŠ¨ä½œ...",
                video=ref,
                output_path="output_extended.mp4"
            )

            # 3. å»¶é•¿è§†é¢‘ï¼ˆä½¿ç”¨æœ¬åœ°æ–‡ä»¶ï¼‰
            path3, ref3, uri3 = client.generate_video(
                prompt="ç»§ç»­...",
                video="output.mp4",
                output_path="output_extended2.mp4"
            )
        """
        # åº”ç”¨é™æµ
        if self.rate_limiter:
            self.rate_limiter.acquire(self.VIDEO_MODEL)

        # åˆ¤æ–­æ¨¡å¼ï¼šå¦‚æœæä¾›äº† video å‚æ•°åˆ™ä¸ºå»¶é•¿æ¨¡å¼
        is_extend_mode = video is not None

        if is_extend_mode:
            # ===== å»¶é•¿æ¨¡å¼ =====
            # å»¶é•¿æ¨¡å¼å¿…é¡»ä½¿ç”¨ 720pï¼Œå›ºå®š 7 ç§’
            config_params = {
                "number_of_videos": 1,
                "resolution": "720p",
                "duration_seconds": 7,
                "generate_audio": True,
            }

            # Vertex AI æ¨¡å¼éœ€è¦ output_gcs_uri
            # å¦‚æœæœªæä¾›ï¼Œè‡ªåŠ¨ä»ç¯å¢ƒå˜é‡æ„å»º
            if self.backend == 'vertex':
                if not output_gcs_uri and self.gcs_bucket:
                    # æ ¹æ® output_path ç”Ÿæˆ GCS URI
                    if output_path:
                        filename = Path(output_path).name
                    else:
                        import uuid
                        filename = f"extend_{uuid.uuid4().hex[:8]}.mp4"
                    output_gcs_uri = f"gs://{self.gcs_bucket}/video_extend/{filename}"

                if output_gcs_uri:
                    config_params["output_gcs_uri"] = output_gcs_uri
                else:
                    raise ValueError(
                        "Vertex AI æ¨¡å¼ä¸‹å»¶é•¿è§†é¢‘éœ€è¦ output_gcs_uri æˆ–è®¾ç½® VERTEX_GCS_BUCKET ç¯å¢ƒå˜é‡"
                    )

            config = self.types.GenerateVideosConfig(**config_params)

            # å‡†å¤‡è§†é¢‘å‚æ•°
            video_param, video_bytes = self._prepare_video_param(video)

            if self.backend == 'vertex':
                # Vertex AI æ¨¡å¼ï¼šä½¿ç”¨ source å‚æ•°å’Œ video_bytes
                if video_bytes is None:
                    raise ValueError(
                        "Vertex AI æ¨¡å¼ä¸‹å»¶é•¿è§†é¢‘éœ€è¦æä¾› video_bytesï¼Œ"
                        "è¯·ä¼ å…¥æœ¬åœ°è§†é¢‘æ–‡ä»¶è·¯å¾„æˆ–åŒ…å« video_bytes çš„ Video å¯¹è±¡"
                    )

                source = self.types.GenerateVideosSource(
                    prompt=prompt,
                    video=self.types.Video(
                        video_bytes=video_bytes,
                        mime_type="video/mp4",
                    ),
                )

                operation = self.client.models.generate_videos(
                    model=self.VIDEO_MODEL,
                    source=source,
                    config=config
                )
            else:
                # AI Studio æ¨¡å¼ï¼šä½¿ç”¨ video å‚æ•°
                operation = self.client.models.generate_videos(
                    model=self.VIDEO_MODEL,
                    video=video_param,
                    prompt=prompt,
                    config=config
                )
        else:
            # ===== ç”Ÿæˆæ¨¡å¼ =====
            # æ„å»ºé…ç½®
            config = self.types.GenerateVideosConfig(
                aspect_ratio=aspect_ratio,
                resolution=resolution,
                duration_seconds=duration_seconds,
                negative_prompt=negative_prompt
            )

            # å‡†å¤‡èµ·å§‹å¸§
            image_param = self._prepare_image_param(start_image)

            # è°ƒç”¨ API
            operation = self.client.models.generate_videos(
                model=self.VIDEO_MODEL,
                prompt=prompt,
                image=image_param,
                config=config
            )

        # ç­‰å¾…å®Œæˆ
        elapsed = 0
        mode_text = "æ‰©å±•" if is_extend_mode else "ç”Ÿæˆ"
        while not operation.done:
            if elapsed >= max_wait_time:
                raise TimeoutError(f"è§†é¢‘{mode_text}è¶…æ—¶ï¼ˆ{max_wait_time}ç§’ï¼‰")
            time.sleep(poll_interval)
            elapsed += poll_interval
            operation = self.client.operations.get(operation)
            print(f"è§†é¢‘{mode_text}ä¸­... å·²ç­‰å¾… {elapsed} ç§’")

        # æ£€æŸ¥ç»“æœ
        if not operation.response or not operation.response.generated_videos:
            print(f"DEBUG: Operation details: {operation}")
            if hasattr(operation, 'error') and operation.error:
                raise RuntimeError(f"è§†é¢‘{mode_text}å¤±è´¥: {operation.error}")
            raise RuntimeError(f"è§†é¢‘{mode_text}å¤±è´¥: API è¿”å›ç©ºç»“æœ")

        # è·å–ç”Ÿæˆçš„è§†é¢‘å’Œå¼•ç”¨
        generated_video = operation.response.generated_videos[0]
        video_ref = generated_video.video
        video_uri = video_ref.uri if video_ref else None

        if output_path:
            output_path = Path(output_path)
            output_path.parent.mkdir(parents=True, exist_ok=True)

            if is_extend_mode and self.backend == 'vertex' and output_gcs_uri:
                # ä» GCS ä¸‹è½½è§†é¢‘
                from google.cloud import storage

                # ä½¿ç”¨è¿”å›çš„å®é™… URI
                actual_gcs_uri = video_uri if video_uri else output_gcs_uri

                # è§£æ gs://bucket-name/path/to/file
                gcs_parts = actual_gcs_uri.replace('gs://', '').split('/', 1)
                bucket_name = gcs_parts[0]
                blob_name = gcs_parts[1] if len(gcs_parts) > 1 else ''

                storage_client = storage.Client(
                    credentials=self.credentials,
                    project=self.project_id
                )
                bucket = storage_client.bucket(bucket_name)
                blob = bucket.blob(blob_name)
                blob.download_to_filename(str(output_path))
                print(f"âœ“ å·²ä» {actual_gcs_uri} ä¸‹è½½è§†é¢‘")
            else:
                # ä¸‹è½½è§†é¢‘æ–‡ä»¶
                self._download_video(video_ref, output_path)

            return output_path, video_ref, video_uri

        return None, video_ref, video_uri

    def _prepare_video_generate_config(
        self,
        aspect_ratio: str,
        resolution: str,
        duration_seconds: str,
        negative_prompt: str
    ):
        """æ„å»ºè§†é¢‘ç”Ÿæˆé…ç½®"""
        return self.types.GenerateVideosConfig(
            aspect_ratio=aspect_ratio,
            resolution=resolution,
            duration_seconds=duration_seconds,
            negative_prompt=negative_prompt
        )

    def _prepare_video_extend_config(
        self,
        output_gcs_uri: Optional[str] = None
    ):
        """æ„å»ºè§†é¢‘å»¶é•¿é…ç½®"""
        config_params = {
            "number_of_videos": 1,
            "resolution": "720p",
            "duration_seconds": 7,
            "generate_audio": True,
        }
        if output_gcs_uri:
            config_params["output_gcs_uri"] = output_gcs_uri
        return self.types.GenerateVideosConfig(**config_params)

    def _process_video_result(
        self,
        operation,
        output_path: Optional[Union[str, Path]],
        is_extend_mode: bool,
        output_gcs_uri: Optional[str] = None
    ) -> tuple:
        """å¤„ç†è§†é¢‘ç”Ÿæˆç»“æœï¼Œä¸‹è½½å¹¶ä¿å­˜"""
        mode_text = "æ‰©å±•" if is_extend_mode else "ç”Ÿæˆ"

        # æ£€æŸ¥ç»“æœ
        if not operation.response or not operation.response.generated_videos:
            print(f"DEBUG: Operation details: {operation}")
            if hasattr(operation, 'error') and operation.error:
                raise RuntimeError(f"è§†é¢‘{mode_text}å¤±è´¥: {operation.error}")
            raise RuntimeError(f"è§†é¢‘{mode_text}å¤±è´¥: API è¿”å›ç©ºç»“æœ")

        # è·å–ç”Ÿæˆçš„è§†é¢‘å’Œå¼•ç”¨
        generated_video = operation.response.generated_videos[0]
        video_ref = generated_video.video
        video_uri = video_ref.uri if video_ref else None

        if output_path:
            output_path = Path(output_path)
            output_path.parent.mkdir(parents=True, exist_ok=True)

            if is_extend_mode and self.backend == 'vertex' and output_gcs_uri:
                # ä» GCS ä¸‹è½½è§†é¢‘
                from google.cloud import storage

                # ä½¿ç”¨è¿”å›çš„å®é™… URI
                actual_gcs_uri = video_uri if video_uri else output_gcs_uri

                # è§£æ gs://bucket-name/path/to/file
                gcs_parts = actual_gcs_uri.replace('gs://', '').split('/', 1)
                bucket_name = gcs_parts[0]
                blob_name = gcs_parts[1] if len(gcs_parts) > 1 else ''

                storage_client = storage.Client(
                    credentials=self.credentials,
                    project=self.project_id
                )
                bucket = storage_client.bucket(bucket_name)
                blob = bucket.blob(blob_name)
                blob.download_to_filename(str(output_path))
                print(f"âœ“ å·²ä» {actual_gcs_uri} ä¸‹è½½è§†é¢‘")
            else:
                # ä¸‹è½½è§†é¢‘æ–‡ä»¶
                self._download_video(video_ref, output_path)

            return output_path, video_ref, video_uri

        return None, video_ref, video_uri

    @with_retry_async(max_attempts=3, backoff_seconds=(2, 4, 8))
    async def generate_video_async(
        self,
        prompt: str,
        # ç”Ÿæˆæ¨¡å¼å‚æ•°
        start_image: Optional[Union[str, Path, Image.Image]] = None,
        reference_images: Optional[List[dict]] = None,
        # å»¶é•¿æ¨¡å¼å‚æ•°
        video: Optional[Union[str, Path]] = None,
        # é…ç½®å‚æ•°
        aspect_ratio: str = "9:16",
        duration_seconds: str = "8",
        resolution: str = "720p",
        negative_prompt: str = "background music, BGM, soundtrack, musical accompaniment",
        output_path: Optional[Union[str, Path]] = None,
        output_gcs_uri: Optional[str] = None,
        poll_interval: int = 10,
        max_wait_time: int = 600
    ) -> tuple:
        """
        å¼‚æ­¥ç”Ÿæˆ/å»¶é•¿è§†é¢‘

        ä½¿ç”¨ genai åŸç”Ÿå¼‚æ­¥ API: client.aio.models.generate_videos()

        Args:
            prompt: è§†é¢‘ç”Ÿæˆ/å»¶é•¿æç¤ºè¯ï¼ˆæ”¯æŒå¯¹è¯å’ŒéŸ³æ•ˆæè¿°ï¼‰

            # ç”Ÿæˆæ¨¡å¼å‚æ•°
            start_image: èµ·å§‹å¸§å›¾ç‰‡ï¼ˆimage-to-video æ¨¡å¼ï¼‰
            reference_images: å‚è€ƒå›¾ç‰‡åˆ—è¡¨ï¼Œæ ¼å¼ä¸º [{"image": path, "description": str}]

            # å»¶é•¿æ¨¡å¼å‚æ•°
            video: è¦å»¶é•¿çš„è§†é¢‘ï¼Œæ”¯æŒä»¥ä¸‹ç±»å‹ï¼š
                - Video å¯¹è±¡ï¼ˆæ¥è‡ªä¹‹å‰è°ƒç”¨çš„è¿”å›å€¼ï¼‰
                - URI å­—ç¬¦ä¸²ï¼ˆgs:// æˆ– https://ï¼‰
                - æœ¬åœ°è§†é¢‘æ–‡ä»¶è·¯å¾„

            # é…ç½®å‚æ•°
            aspect_ratio: å®½é«˜æ¯”ï¼Œé»˜è®¤ 9:16ï¼ˆç”Ÿæˆæ¨¡å¼ä½¿ç”¨ï¼‰
            duration_seconds: è§†é¢‘æ—¶é•¿ï¼Œå¯é€‰ "4", "6", "8"ï¼ˆç”Ÿæˆæ¨¡å¼ä½¿ç”¨ï¼‰
            resolution: åˆ†è¾¨ç‡ï¼Œå¯é€‰ "720p", "1080p", "4k"ï¼ˆå»¶é•¿æ¨¡å¼å¼ºåˆ¶ 720pï¼‰
            negative_prompt: è´Ÿé¢æç¤ºè¯ï¼ŒæŒ‡å®šä¸æƒ³è¦çš„å…ƒç´ ï¼ˆé»˜è®¤ç¦æ­¢ BGMï¼‰
            output_path: æœ¬åœ°è¾“å‡ºè·¯å¾„
            output_gcs_uri: GCS è¾“å‡ºè·¯å¾„ï¼ˆVertex AI å»¶é•¿æ¨¡å¼å¿…é¡»è®¾ç½®ï¼‰
            poll_interval: è½®è¯¢é—´éš”ï¼ˆç§’ï¼‰
            max_wait_time: æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰

        Returns:
            (output_path, video_ref, video_uri) ä¸‰å…ƒç»„
        """
        # åº”ç”¨é™æµ
        if self.rate_limiter:
            await self.rate_limiter.acquire_async(self.VIDEO_MODEL)

        # åˆ¤æ–­æ¨¡å¼ï¼šå¦‚æœæä¾›äº† video å‚æ•°åˆ™ä¸ºå»¶é•¿æ¨¡å¼
        is_extend_mode = video is not None

        if is_extend_mode:
            # ===== å»¶é•¿æ¨¡å¼ =====
            # Vertex AI æ¨¡å¼éœ€è¦ output_gcs_uri
            if self.backend == 'vertex':
                if not output_gcs_uri and self.gcs_bucket:
                    if output_path:
                        filename = Path(output_path).name
                    else:
                        import uuid
                        filename = f"extend_{uuid.uuid4().hex[:8]}.mp4"
                    output_gcs_uri = f"gs://{self.gcs_bucket}/video_extend/{filename}"

                if not output_gcs_uri:
                    raise ValueError(
                        "Vertex AI æ¨¡å¼ä¸‹å»¶é•¿è§†é¢‘éœ€è¦ output_gcs_uri æˆ–è®¾ç½® VERTEX_GCS_BUCKET ç¯å¢ƒå˜é‡"
                    )

            config = self._prepare_video_extend_config(output_gcs_uri)

            # å‡†å¤‡è§†é¢‘å‚æ•°
            video_param, video_bytes = self._prepare_video_param(video)

            if self.backend == 'vertex':
                if video_bytes is None:
                    raise ValueError(
                        "Vertex AI æ¨¡å¼ä¸‹å»¶é•¿è§†é¢‘éœ€è¦æä¾› video_bytesï¼Œ"
                        "è¯·ä¼ å…¥æœ¬åœ°è§†é¢‘æ–‡ä»¶è·¯å¾„æˆ–åŒ…å« video_bytes çš„ Video å¯¹è±¡"
                    )

                source = self.types.GenerateVideosSource(
                    prompt=prompt,
                    video=self.types.Video(
                        video_bytes=video_bytes,
                        mime_type="video/mp4",
                    ),
                )

                operation = await self.client.aio.models.generate_videos(
                    model=self.VIDEO_MODEL,
                    source=source,
                    config=config
                )
            else:
                # AI Studio æ¨¡å¼
                operation = await self.client.aio.models.generate_videos(
                    model=self.VIDEO_MODEL,
                    video=video_param,
                    prompt=prompt,
                    config=config
                )
        else:
            # ===== ç”Ÿæˆæ¨¡å¼ =====
            config = self._prepare_video_generate_config(
                aspect_ratio, resolution, duration_seconds, negative_prompt
            )

            # å‡†å¤‡èµ·å§‹å¸§
            image_param = self._prepare_image_param(start_image)

            # è°ƒç”¨å¼‚æ­¥ API
            operation = await self.client.aio.models.generate_videos(
                model=self.VIDEO_MODEL,
                prompt=prompt,
                image=image_param,
                config=config
            )

        # å¼‚æ­¥ç­‰å¾…å®Œæˆ
        elapsed = 0
        mode_text = "æ‰©å±•" if is_extend_mode else "ç”Ÿæˆ"
        while not operation.done:
            if elapsed >= max_wait_time:
                raise TimeoutError(f"è§†é¢‘{mode_text}è¶…æ—¶ï¼ˆ{max_wait_time}ç§’ï¼‰")
            await asyncio.sleep(poll_interval)
            elapsed += poll_interval
            operation = await self.client.aio.operations.get(operation)
            print(f"è§†é¢‘{mode_text}ä¸­... å·²ç­‰å¾… {elapsed} ç§’")

        return self._process_video_result(operation, output_path, is_extend_mode, output_gcs_uri)

    def _prepare_text_config(
        self,
        response_schema: Optional[Dict]
    ) -> Optional[Dict]:
        """æ„å»ºæ–‡æœ¬ç”Ÿæˆé…ç½®"""
        if response_schema:
            return {
                "response_mime_type": "application/json",
                "response_json_schema": response_schema,
            }
        return None

    def _process_text_response(self, response) -> str:
        """è§£ææ–‡æœ¬ç”Ÿæˆå“åº”"""
        return response.text

    @with_retry(max_attempts=3, backoff_seconds=(2, 4, 8))
    def generate_text(
        self,
        prompt: str,
        model: str = "gemini-2.0-flash",
        response_schema: Optional[Dict] = None,
    ) -> str:
        """
        ç”Ÿæˆæ–‡æœ¬å†…å®¹ï¼Œæ”¯æŒ Structured Outputs

        Args:
            prompt: æç¤ºè¯
            model: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä½¿ç”¨ flash æ¨¡å‹
            response_schema: å¯é€‰çš„ JSON Schemaï¼Œç”¨äº Structured Outputs

        Returns:
            ç”Ÿæˆçš„æ–‡æœ¬å†…å®¹
        """
        config = self._prepare_text_config(response_schema)
        response = self.client.models.generate_content(
            model=model,
            contents=prompt,
            config=config,
        )
        return self._process_text_response(response)

    @with_retry_async(max_attempts=3, backoff_seconds=(2, 4, 8))
    async def generate_text_async(
        self,
        prompt: str,
        model: str = "gemini-2.0-flash",
        response_schema: Optional[Dict] = None,
    ) -> str:
        """
        å¼‚æ­¥ç”Ÿæˆæ–‡æœ¬å†…å®¹ï¼Œæ”¯æŒ Structured Outputs

        ä½¿ç”¨ genai åŸç”Ÿå¼‚æ­¥ API: client.aio.models.generate_content()

        Args:
            prompt: æç¤ºè¯
            model: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä½¿ç”¨ flash æ¨¡å‹
            response_schema: å¯é€‰çš„ JSON Schemaï¼Œç”¨äº Structured Outputs

        Returns:
            ç”Ÿæˆçš„æ–‡æœ¬å†…å®¹
        """
        config = self._prepare_text_config(response_schema)
        response = await self.client.aio.models.generate_content(
            model=model,
            contents=prompt,
            config=config,
        )
        return self._process_text_response(response)

    def _download_video(self, video_ref, output_path: Path) -> None:
        """
        ä¸‹è½½è§†é¢‘åˆ°æœ¬åœ°æ–‡ä»¶

        Args:
            video_ref: Video å¯¹è±¡
            output_path: è¾“å‡ºè·¯å¾„
        """
        if self.backend == 'vertex':
            # Vertex AI æ¨¡å¼ï¼šä» video_bytes ç›´æ¥ä¿å­˜
            if video_ref and hasattr(video_ref, 'video_bytes') and video_ref.video_bytes:
                with open(output_path, 'wb') as f:
                    f.write(video_ref.video_bytes)
            elif video_ref and hasattr(video_ref, 'uri') and video_ref.uri:
                # å¦‚æœæ²¡æœ‰ video_bytesï¼Œå°è¯•ä» URI ä¸‹è½½
                import urllib.request
                urllib.request.urlretrieve(video_ref.uri, str(output_path))
            else:
                raise RuntimeError("è§†é¢‘ç”ŸæˆæˆåŠŸä½†æ— æ³•è·å–è§†é¢‘æ•°æ®")
        else:
            # AI Studio æ¨¡å¼ï¼šä½¿ç”¨ files.download
            self.client.files.download(file=video_ref)
            video_ref.save(str(output_path))

    def _prepare_image_param(
        self,
        image: Optional[Union[str, Path, Image.Image]]
    ):
        """
        å‡†å¤‡å›¾ç‰‡å‚æ•°ç”¨äº API è°ƒç”¨

        Args:
            image: å›¾ç‰‡è·¯å¾„æˆ– PIL Image å¯¹è±¡

        Returns:
            types.Image å¯¹è±¡æˆ– None
        """
        if image is None:
            return None

        mime_type_png = 'image/png'

        if isinstance(image, (str, Path)):
            # è¯»å–å›¾ç‰‡æ–‡ä»¶ä¸º bytes
            with open(image, 'rb') as f:
                image_bytes = f.read()
            # ç¡®å®š MIME ç±»å‹
            suffix = Path(image).suffix.lower()
            mime_types = {
                '.png': mime_type_png,
                '.jpg': 'image/jpeg',
                '.jpeg': 'image/jpeg',
                '.gif': 'image/gif',
                '.webp': 'image/webp'
            }
            mime_type = mime_types.get(suffix, mime_type_png)
            return self.types.Image(
                image_bytes=image_bytes,
                mime_type=mime_type
            )
        elif isinstance(image, Image.Image):
            # å°† PIL Image è½¬æ¢ä¸º bytes
            buffer = io.BytesIO()
            image.save(buffer, format='PNG')
            image_bytes = buffer.getvalue()
            return self.types.Image(
                image_bytes=image_bytes,
                mime_type=mime_type_png
            )
        else:
            return image

    def _prepare_video_param(self, video):
        """
        ç»Ÿä¸€å¤„ç† video å‚æ•°ï¼Œæ”¯æŒå¤šç§è¾“å…¥ç±»å‹

        Args:
            video: è§†é¢‘è¾“å…¥ï¼Œæ”¯æŒä»¥ä¸‹ç±»å‹ï¼š
                - None: è¿”å› (None, None)
                - Video å¯¹è±¡: ç›´æ¥ä½¿ç”¨
                - URI å­—ç¬¦ä¸² (gs:// æˆ– https://): åŒ…è£…ä¸º Video å¯¹è±¡
                - æœ¬åœ°æ–‡ä»¶è·¯å¾„: è¯»å–ä¸º video_bytes

        Returns:
            (video_param, video_bytes) å…ƒç»„
            - video_param: ç”¨äº API è°ƒç”¨çš„å‚æ•°
            - video_bytes: è§†é¢‘äºŒè¿›åˆ¶æ•°æ®ï¼ˆVertex AI æ¨¡å¼ä¸‹è½½æ—¶ä½¿ç”¨ï¼‰
        """
        if video is None:
            return None, None

        # Video å¯¹è±¡ - ç›´æ¥ä½¿ç”¨
        if hasattr(video, 'uri') or hasattr(video, 'video_bytes'):
            video_bytes = getattr(video, 'video_bytes', None)
            return video, video_bytes

        # URI å­—ç¬¦ä¸²
        if isinstance(video, str) and ('gs://' in video or '://' in video):
            return self.types.Video(uri=video, mime_type="video/mp4"), None

        # æœ¬åœ°æ–‡ä»¶è·¯å¾„
        if isinstance(video, (str, Path)) and Path(video).exists():
            with open(video, 'rb') as f:
                video_bytes = f.read()
            return self.types.Video(
                video_bytes=video_bytes,
                mime_type="video/mp4"
            ), video_bytes

        raise ValueError(f"æ— æ•ˆçš„ video å‚æ•°: {video}")
